{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/spt1cg6TxB1cj5BnPl01",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaseelkt007/ML/blob/master/Diabetic_Retinopathy_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ugPoHZDl-NPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c663c6-1e4e-4e13-ef36-01a7d18e098b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from multiprocessing import Pool\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "sample_data_path = '/content/drive/MyDrive/sample'\n",
        "output_folder = '/content/drive/MyDrive/sample/preprocessed_samples'\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    #transforms.Resize((256,256)),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness= 0.2, contrast = 0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456,0.406], std= [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "def trim(image):\n",
        "\n",
        "    percentage = 0.02\n",
        "    img = np.array(image)\n",
        "    img_gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY) # Convert to grayscale to simply the process\n",
        "    # create the binary mask , to get the background from actual content\n",
        "    img_gray = img_gray > 0.1 * np.mean(img_gray[img_gray!=0])\n",
        "    # calculate the row wise and column wise sums to find where the significant content exists\n",
        "    row_sums = np.sum(img_gray, axis = 1)\n",
        "    col_sums = np.sum(img_gray, axis = 0)\n",
        "    rows = np.where(row_sums > img.shape[1] * percentage)[0] # return the rows index of rows which contain atleast 2% of its content\n",
        "    cols = np.where (col_sums > img.shape[0] * percentage)[0]\n",
        "    # find the min and max rows and columns for croping\n",
        "    min_row, min_col = np.min(rows), np.min(cols)\n",
        "    max_row, max_col = np.max(rows), np.max(cols)\n",
        "    im_crop = img[min_row : max_row +1 , min_col : max_col+1]\n",
        "    return Image.fromarray(im_crop)\n",
        "\n",
        "def resize_main_aspect(image, desired_size):\n",
        "    old_size = image.size\n",
        "    ratio = float(desired_size)/ max(old_size) # resize ratio\n",
        "    new_size = tuple([int(x * ratio) for x in old_size]) # (N,M) N,M are new size\n",
        "    im = image.resize(new_size, Image.LANCZOS) # a filter to smooth image when resize, helps to reduce artifacts in the reduced image\n",
        "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "    new_im.paste(im, ((desired_size - new_size[0])//2 , (desired_size - new_size[1])//2)) # paster the image on the new square background\n",
        "    return new_im\n",
        "\n",
        "def save_single(args): # helpfull for multiprocessing\n",
        "    img_file, input_path_folder, output_path_folder, output_size = args\n",
        "    image_org = Image.open(os.path.join(input_path_folder, img_file))\n",
        "    image = trim(image_org)\n",
        "    image = resize_main_aspect(image, desired_size= output_size[0])\n",
        "    image.save(os.path.join(output_path_folder , img_file))\n",
        "\n",
        "\n",
        "\n",
        "def multi_image_resize(input_path_folder, output_path_folder, output_size=None):\n",
        "    if not output_size:\n",
        "        warnings.warn(\"Need to specify output_size! For example: output_size=100\")\n",
        "        exit()\n",
        "\n",
        "    if not os.path.exists(output_path_folder):\n",
        "        os.makedirs(output_path_folder)\n",
        "\n",
        "    jobs = [\n",
        "        (file, input_path_folder, output_path_folder, output_size)\n",
        "        for file in os.listdir(input_path_folder)\n",
        "        if os.path.isfile(os.path.join(input_path_folder,file))\n",
        "    ]\n",
        "\n",
        "    with Pool() as p:\n",
        "        list(tqdm(p.imap_unordered(save_single, jobs), total=len(jobs)))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #multi_image_resize(sample_data_path, output_folder, output_size = (256,256))\n",
        "    pass\n",
        "\n",
        "def preprocess_images(data_path, transform):\n",
        "    processed_images = []\n",
        "    for img_name in os.listdir(data_path):\n",
        "        img_path = os.path.join(data_path, img_name)\n",
        "        image = Image.open(img_path)\n",
        "        image = trim(image)\n",
        "        image_resized = resize_main_aspect(image, desired_size=256)\n",
        "        image = transform(image_resized)\n",
        "        processed_images.append(image)\n",
        "    return processed_images\n",
        "\n",
        "#processed_images = preprocess_images(sample_data_path, transform)\n",
        "\n",
        "def show_images(images, n=5):\n",
        "    fig, axs = plt.subplots(1, n , figsize=(15,5))\n",
        "    for i , img in enumerate(images[:n]):\n",
        "        img = img.permute(1,2,0) # change from C, H, W to H, W, C\n",
        "        img = torch.clamp(img * torch.tensor([0.229,0.224,0.225]) +\n",
        "                          torch.tensor([0.485,0.456,0.406]), 0,1) # denormalize\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "#show_images(processed_images,n=5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LUTCQCOn-05P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c7149c-bd17-4e56-bc80-13500e47e89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [04:01<00:00,  1.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "file_path = '/content/train.csv'\n",
        "\n",
        "filtered_image_names_0 = []\n",
        "filtered_image_names_1 = []\n",
        "filtered_image_names_2 = []\n",
        "filtered_image_names_3 = []\n",
        "filtered_image_names_4 = []\n",
        "\n",
        "#open csv file\n",
        "with open(file_path,  encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file) #csv_reader is an iterator\n",
        "    header = next(csv_reader)  # read the header\n",
        "    #print(\"Header:\", header)\n",
        "\n",
        "    # find the column index of \"Image name\" and \"Retinopathy grade\"\n",
        "    image_name_index = header.index(\"Image name\")\n",
        "    grade_index = header.index(\"Retinopathy grade\")\n",
        "\n",
        "\n",
        "    for row in csv_reader: # read each row of it\n",
        "        if row[grade_index] == '0':\n",
        "            filtered_image_names_0.append(row[image_name_index])\n",
        "        elif row[grade_index] == '1':\n",
        "            filtered_image_names_1.append(row[image_name_index])\n",
        "        elif row[grade_index] == '2':\n",
        "            filtered_image_names_2.append(row[image_name_index])\n",
        "        elif row[grade_index] == '3':\n",
        "            filtered_image_names_3.append(row[image_name_index])\n",
        "        elif row[grade_index] == '4':\n",
        "            filtered_image_names_4.append(row[image_name_index])\n",
        "\n",
        "for i in range(5):\n",
        "    name = f\"filtered_image_names_{i}\"\n",
        "\n",
        "    print(f\"{name}: {globals()[name]}\")"
      ],
      "metadata": {
        "id": "PRkQqtOdkZp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6382b136-54ce-4888-ae5f-fdac48deb6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filtered_image_names_0: ['IDRiD_118', 'IDRiD_138', 'IDRiD_139', 'IDRiD_140', 'IDRiD_141', 'IDRiD_142', 'IDRiD_143', 'IDRiD_144', 'IDRiD_145', 'IDRiD_146', 'IDRiD_147', 'IDRiD_148', 'IDRiD_149', 'IDRiD_150', 'IDRiD_151', 'IDRiD_152', 'IDRiD_153', 'IDRiD_154', 'IDRiD_155', 'IDRiD_156', 'IDRiD_157', 'IDRiD_158', 'IDRiD_159', 'IDRiD_160', 'IDRiD_161', 'IDRiD_162', 'IDRiD_163', 'IDRiD_164', 'IDRiD_165', 'IDRiD_166', 'IDRiD_167', 'IDRiD_168', 'IDRiD_169', 'IDRiD_170', 'IDRiD_171', 'IDRiD_172', 'IDRiD_173', 'IDRiD_174', 'IDRiD_175', 'IDRiD_176', 'IDRiD_177', 'IDRiD_179', 'IDRiD_181', 'IDRiD_182', 'IDRiD_184', 'IDRiD_190', 'IDRiD_193', 'IDRiD_195', 'IDRiD_197', 'IDRiD_199', 'IDRiD_200', 'IDRiD_202', 'IDRiD_204', 'IDRiD_205', 'IDRiD_206', 'IDRiD_209', 'IDRiD_210', 'IDRiD_211', 'IDRiD_212', 'IDRiD_213', 'IDRiD_214', 'IDRiD_217', 'IDRiD_218', 'IDRiD_219', 'IDRiD_220', 'IDRiD_221', 'IDRiD_222', 'IDRiD_223', 'IDRiD_225', 'IDRiD_226', 'IDRiD_227', 'IDRiD_228', 'IDRiD_229', 'IDRiD_230', 'IDRiD_233', 'IDRiD_234', 'IDRiD_235', 'IDRiD_238', 'IDRiD_243', 'IDRiD_244', 'IDRiD_249', 'IDRiD_250', 'IDRiD_251', 'IDRiD_255', 'IDRiD_257', 'IDRiD_258', 'IDRiD_259', 'IDRiD_264', 'IDRiD_267', 'IDRiD_268', 'IDRiD_273', 'IDRiD_274', 'IDRiD_275', 'IDRiD_276', 'IDRiD_287', 'IDRiD_288', 'IDRiD_292', 'IDRiD_295', 'IDRiD_297', 'IDRiD_298', 'IDRiD_305', 'IDRiD_307', 'IDRiD_312', 'IDRiD_315', 'IDRiD_316', 'IDRiD_317', 'IDRiD_318', 'IDRiD_331', 'IDRiD_335', 'IDRiD_336', 'IDRiD_342', 'IDRiD_345', 'IDRiD_346', 'IDRiD_351', 'IDRiD_352', 'IDRiD_353', 'IDRiD_355', 'IDRiD_358', 'IDRiD_359', 'IDRiD_365', 'IDRiD_367', 'IDRiD_370', 'IDRiD_373', 'IDRiD_378', 'IDRiD_381', 'IDRiD_382', 'IDRiD_386', 'IDRiD_387', 'IDRiD_393', 'IDRiD_395', 'IDRiD_396', 'IDRiD_399', 'IDRiD_400', 'IDRiD_406']\n",
            "filtered_image_names_1: ['IDRiD_021', 'IDRiD_079', 'IDRiD_105', 'IDRiD_194', 'IDRiD_198', 'IDRiD_203', 'IDRiD_256', 'IDRiD_265', 'IDRiD_266', 'IDRiD_279', 'IDRiD_290', 'IDRiD_291', 'IDRiD_301', 'IDRiD_302', 'IDRiD_304', 'IDRiD_379', 'IDRiD_388', 'IDRiD_402', 'IDRiD_403', 'IDRiD_408']\n",
            "filtered_image_names_2: ['IDRiD_003', 'IDRiD_016', 'IDRiD_018', 'IDRiD_019', 'IDRiD_020', 'IDRiD_029', 'IDRiD_037', 'IDRiD_038', 'IDRiD_041', 'IDRiD_042', 'IDRiD_043', 'IDRiD_044', 'IDRiD_045', 'IDRiD_047', 'IDRiD_048', 'IDRiD_050', 'IDRiD_051', 'IDRiD_052', 'IDRiD_056', 'IDRiD_058', 'IDRiD_059', 'IDRiD_060', 'IDRiD_061', 'IDRiD_063', 'IDRiD_064', 'IDRiD_068', 'IDRiD_069', 'IDRiD_071', 'IDRiD_072', 'IDRiD_073', 'IDRiD_074', 'IDRiD_076', 'IDRiD_078', 'IDRiD_080', 'IDRiD_082', 'IDRiD_083', 'IDRiD_084', 'IDRiD_085', 'IDRiD_087', 'IDRiD_091', 'IDRiD_092', 'IDRiD_093', 'IDRiD_094', 'IDRiD_097', 'IDRiD_102', 'IDRiD_103', 'IDRiD_106', 'IDRiD_107', 'IDRiD_109', 'IDRiD_113', 'IDRiD_116', 'IDRiD_117', 'IDRiD_120', 'IDRiD_121', 'IDRiD_122', 'IDRiD_123', 'IDRiD_124', 'IDRiD_125', 'IDRiD_126', 'IDRiD_127', 'IDRiD_128', 'IDRiD_129', 'IDRiD_130', 'IDRiD_131', 'IDRiD_132', 'IDRiD_133', 'IDRiD_134', 'IDRiD_135', 'IDRiD_136', 'IDRiD_137', 'IDRiD_183', 'IDRiD_185', 'IDRiD_186', 'IDRiD_187', 'IDRiD_188', 'IDRiD_191', 'IDRiD_196', 'IDRiD_201', 'IDRiD_208', 'IDRiD_215', 'IDRiD_216', 'IDRiD_231', 'IDRiD_232', 'IDRiD_236', 'IDRiD_237', 'IDRiD_241', 'IDRiD_242', 'IDRiD_245', 'IDRiD_247', 'IDRiD_248', 'IDRiD_252', 'IDRiD_260', 'IDRiD_261', 'IDRiD_262', 'IDRiD_263', 'IDRiD_270', 'IDRiD_280', 'IDRiD_281', 'IDRiD_282', 'IDRiD_283', 'IDRiD_284', 'IDRiD_293', 'IDRiD_294', 'IDRiD_300', 'IDRiD_303', 'IDRiD_310', 'IDRiD_311', 'IDRiD_319', 'IDRiD_322', 'IDRiD_325', 'IDRiD_326', 'IDRiD_328', 'IDRiD_332', 'IDRiD_333', 'IDRiD_337', 'IDRiD_338', 'IDRiD_340', 'IDRiD_343', 'IDRiD_348', 'IDRiD_350', 'IDRiD_360', 'IDRiD_363', 'IDRiD_374', 'IDRiD_375', 'IDRiD_391', 'IDRiD_397', 'IDRiD_398', 'IDRiD_401', 'IDRiD_404', 'IDRiD_405', 'IDRiD_407', 'IDRiD_409', 'IDRiD_410', 'IDRiD_411', 'IDRiD_412', 'IDRiD_413']\n",
            "filtered_image_names_3: ['IDRiD_001', 'IDRiD_002', 'IDRiD_004', 'IDRiD_009', 'IDRiD_011', 'IDRiD_012', 'IDRiD_013', 'IDRiD_023', 'IDRiD_025', 'IDRiD_026', 'IDRiD_034', 'IDRiD_035', 'IDRiD_036', 'IDRiD_039', 'IDRiD_040', 'IDRiD_049', 'IDRiD_055', 'IDRiD_057', 'IDRiD_065', 'IDRiD_066', 'IDRiD_075', 'IDRiD_077', 'IDRiD_088', 'IDRiD_095', 'IDRiD_098', 'IDRiD_099', 'IDRiD_101', 'IDRiD_108', 'IDRiD_110', 'IDRiD_112', 'IDRiD_114', 'IDRiD_115', 'IDRiD_180', 'IDRiD_192', 'IDRiD_207', 'IDRiD_253', 'IDRiD_269', 'IDRiD_271', 'IDRiD_277', 'IDRiD_278', 'IDRiD_296', 'IDRiD_299', 'IDRiD_306', 'IDRiD_308', 'IDRiD_309', 'IDRiD_314', 'IDRiD_320', 'IDRiD_321', 'IDRiD_323', 'IDRiD_324', 'IDRiD_327', 'IDRiD_329', 'IDRiD_330', 'IDRiD_334', 'IDRiD_339', 'IDRiD_341', 'IDRiD_344', 'IDRiD_347', 'IDRiD_349', 'IDRiD_354', 'IDRiD_356', 'IDRiD_357', 'IDRiD_364', 'IDRiD_366', 'IDRiD_368', 'IDRiD_369', 'IDRiD_371', 'IDRiD_372', 'IDRiD_376', 'IDRiD_377', 'IDRiD_380', 'IDRiD_383', 'IDRiD_384', 'IDRiD_385']\n",
            "filtered_image_names_4: ['IDRiD_005', 'IDRiD_006', 'IDRiD_007', 'IDRiD_008', 'IDRiD_010', 'IDRiD_014', 'IDRiD_015', 'IDRiD_017', 'IDRiD_022', 'IDRiD_024', 'IDRiD_027', 'IDRiD_028', 'IDRiD_030', 'IDRiD_031', 'IDRiD_032', 'IDRiD_033', 'IDRiD_046', 'IDRiD_053', 'IDRiD_054', 'IDRiD_062', 'IDRiD_067', 'IDRiD_070', 'IDRiD_081', 'IDRiD_086', 'IDRiD_089', 'IDRiD_090', 'IDRiD_096', 'IDRiD_100', 'IDRiD_104', 'IDRiD_111', 'IDRiD_119', 'IDRiD_178', 'IDRiD_189', 'IDRiD_224', 'IDRiD_239', 'IDRiD_240', 'IDRiD_246', 'IDRiD_254', 'IDRiD_272', 'IDRiD_285', 'IDRiD_286', 'IDRiD_289', 'IDRiD_313', 'IDRiD_361', 'IDRiD_362', 'IDRiD_389', 'IDRiD_390', 'IDRiD_392', 'IDRiD_394']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness= 0.1, contrast=0.1),\n",
        "])\n",
        "\n",
        "preprocessed_folder = '/content/drive/MyDrive/sample/preprocessed_samples'\n",
        "augmented_folder = '/content/drive/MyDrive/sample/aug_train_samples'\n",
        "csv_file_path = '/content/train.csv'\n",
        "\n",
        "if not os.path.exists(augmented_folder):\n",
        "    os.makedirs(augmented_folder)\n",
        "\n",
        "# create output folder structure each class\n",
        "for i in range(5):\n",
        "    class_folder = os.path.join(augmented_folder, f'class_{i}')\n",
        "    os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "# augmentation per class:\n",
        "augmentation_counts = {\n",
        "      '0' : 2, # fewer augumentation for class 0\n",
        "      '1' : 10, # more augmentation\n",
        "      '2' : 2,\n",
        "      '3' : 5, # moderate augmentation for class 3 and 4\n",
        "      '4' : 8\n",
        "  }\n",
        "\n",
        "with open(csv_file_path, encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    header = next(csv_reader)\n",
        "    image_name_index = header.index(\"Image name\")\n",
        "    grade_index = header.index(\"Retinopathy grade\")\n",
        "\n",
        "\n",
        "    #Loop through each row in csv and augment imges based on class\n",
        "    for row in tqdm(csv_reader , desc='Augmenting images', unit='image'):\n",
        "        image_name = row[image_name_index]\n",
        "        label = row[grade_index]\n",
        "\n",
        "        #Load the preprocessed image\n",
        "        img_path = os.path.join(preprocessed_folder, f\"{image_name}.jpg\")\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Warning: {img_path} doesn't exist\")\n",
        "            continue # skip if the file doesn't exist\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        # define where to save the image based on the class\n",
        "        class_folder = os.path.join(augmented_folder, f'class_{label}')\n",
        "        num_augmentation = augmentation_counts[label]\n",
        "\n",
        "        for i in range(num_augmentation):\n",
        "            augmented_image = augmentation_transforms(image)\n",
        "            # save the image to corresponding class folder\n",
        "            aug_image_name = f'{image_name}_aug_{i}.jpg'\n",
        "            augmented_image.save(os.path.join(class_folder, aug_image_name))\n",
        "print(\"Augmentation and saving completed\")"
      ],
      "metadata": {
        "id": "E7BUFjMbkZym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b959ed00-2942-48d7-fa8d-aaee86f0c378"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting images: 413image [00:25, 16.38image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation and saving completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the augmented folder\n",
        "augmented_folder = '/content/drive/MyDrive/sample/aug_train_samples'\n",
        "\n",
        "# Loop through each class folder and count the files\n",
        "for i in range(5):\n",
        "    class_folder = os.path.join(augmented_folder, f'class_{i}')\n",
        "    if os.path.exists(class_folder):\n",
        "        files = os.listdir(class_folder)\n",
        "        print(f\"Number of files in {class_folder}: {len(files)}\")\n",
        "    else:\n",
        "        print(f\"{class_folder} does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZB7dg8e98BJ",
        "outputId": "211fbecb-2599-4f4c-a8de-f15ccfb844f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in /content/drive/MyDrive/sample/aug_train_samples/class_0: 268\n",
            "Number of files in /content/drive/MyDrive/sample/aug_train_samples/class_1: 200\n",
            "Number of files in /content/drive/MyDrive/sample/aug_train_samples/class_2: 272\n",
            "Number of files in /content/drive/MyDrive/sample/aug_train_samples/class_3: 370\n",
            "Number of files in /content/drive/MyDrive/sample/aug_train_samples/class_4: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "TONsnSG6cP0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code in tensorflow\n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define augmentation functions using TensorFlow\n",
        "def augment_image(image):\n",
        "    # Random rotation between -20 and +20 degrees\n",
        "    angle = tf.random.uniform([], minval=-20, maxval=20, dtype=tf.float32) * (3.14159265 / 180.0)\n",
        "    image = tfa.image.rotate(image, angle)\n",
        "\n",
        "    # Random horizontal flip\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    # Color jitter (brightness and contrast adjustments)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "\n",
        "    return image\n",
        "\n",
        "preprocessed_folder = '/content/drive/MyDrive/sample/preprocessed_samples'\n",
        "augmented_folder = '/content/drive/MyDrive/sample/aug_train_samples'\n",
        "csv_file_path = '/content/train.csv'\n",
        "\n",
        "if not os.path.exists(augmented_folder):\n",
        "    os.makedirs(augmented_folder)\n",
        "\n",
        "# Create output folder structure for each class\n",
        "for i in range(5):\n",
        "    class_folder = os.path.join(augmented_folder, f'class_{i}')\n",
        "    os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "# Define the number of augmentations per class\n",
        "augmentation_counts = {\n",
        "    '0': 2,   # Fewer augmentations for class 0\n",
        "    '1': 10,  # More augmentations for class 1\n",
        "    '2': 2,   # Fewer augmentations for class 2\n",
        "    '3': 5,   # Moderate augmentations for class 3\n",
        "    '4': 8    # Moderate augmentations for class 4\n",
        "}\n",
        "\n",
        "# Read the CSV file\n",
        "with open(csv_file_path, encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    header = next(csv_reader)\n",
        "    image_name_index = header.index(\"Image name\")\n",
        "    grade_index = header.index(\"Retinopathy grade\")\n",
        "\n",
        "    # Loop through each row in CSV and augment images based on class\n",
        "    for row in tqdm(csv_reader, desc='Augmenting images', unit='image'):\n",
        "        image_name = row[image_name_index]\n",
        "        label = row[grade_index]\n",
        "\n",
        "        # Load the preprocessed image\n",
        "        img_path = os.path.join(preprocessed_folder, f\"{image_name}.jpg\")\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Warning: {img_path} doesn't exist\")\n",
        "            continue  # Skip if the file doesn't exist\n",
        "        image = Image.open(img_path)\n",
        "        image = tf.keras.preprocessing.image.img_to_array(image)  # Convert PIL image to numpy array\n",
        "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)  # Scale pixel values to [0,1]\n",
        "        # Tensorflow augmentation fn operate effectively with in this range [0 1]\n",
        "        # Define where to save the augmented images based on class label\n",
        "        class_folder = os.path.join(augmented_folder, f'class_{label}')\n",
        "        num_augmentation = augmentation_counts[label]\n",
        "\n",
        "        # Generate and save augmented images\n",
        "        for i in range(num_augmentation):\n",
        "            augmented_image = augment_image(image)\n",
        "            augmented_image = tf.keras.preprocessing.image.array_to_img(augmented_image)  # Convert back to PIL image\n",
        "            aug_image_name = f\"{image_name}_aug_{i}.jpg\"\n",
        "            augmented_image.save(os.path.join(class_folder, aug_image_name))\n",
        "\n",
        "print(\"Augmentation and saving completed.\")"
      ],
      "metadata": {
        "id": "38gKJnlibWLH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}